% Papers should be formatted according to the two-column ACM proceedings
% format.  Each paper should have no more than 12 pages, excluding
% bibliography, in 10pt font. There is no limit on the page count for
% references. Each reference must list all authors of the paper (do not use et
% al). The citations should be in numeric style, e.g., [52]. Submissions should
% be in PDF format and printable on US Letter and A4 sized paper. These
% requirements are all the same as in the previous year.



\def\paperversiondraft{draft}
\def\paperversionblind{blind}
\def\paperversioncamera{camera}

% If no special paper-version is requested, compile in draft mode
\ifx\paperversion\paperversionblind
\else
  \ifx\paperversion\paperversioncamera
  \else
     \def\paperversion{draft}
  \fi
\fi

\def\grammarlyon{on}

\ifx\grammarly\grammarlyon
\def\review{}
\else
\def\review{review,}
\fi

\ifx\paperversion\paperversiondraft
  \documentclass[sigplan,\review anonymous]{acmart}
\fi

\ifx\paperversion\paperversionblind
  \documentclass[sigplan,\review anonymous]{acmart}
\fi

\ifx\paperversion\paperversioncamera
  \documentclass[sigplan]{acmart}\settopmatter{}
\fi

% Most PL conferences are edited by conference-publishing.com. Follow their
% advice to add the following packages.
%
% The first enables the use of UTF-8 as character encoding, which is the
% standard nowadays. The second ensures the use of font encodings that support
% accented characters etc. (Why should I use this?). The mictotype package
% enables certain features 'to­wards ty­po­graph­i­cal per­fec­tion
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{microtype}

\usepackage{xargs}
\usepackage{lipsum}
\usepackage[textsize=tiny]{todonotes}
\usepackage{xparse}
\usepackage{xifthen, xstring}
\usepackage{ulem}
\usepackage{xspace}
\usepackage{minted}
\usemintedstyle{bw}
\usepackage{hyperref}
\hypersetup{colorlinks=true,linkcolor=blue}
\usepackage{mathpartir}
\usepackage{dirtytalk}
\usepackage[ligature, inference]{semantic}

\usepackage{listings}
\usepackage{xcolor}

%New colors defined below
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

%Code listing style named "mystyle"
% https://www.overleaf.com/project/5fc73ba8b2793a82677493d5
% https://tex.stackexchange.com/questions/200208/how-can-i-reduce-the-line-spacing-in-a-listing
\lstdefinestyle{mystyle}{
  commentstyle=\color{gray},
  keywordstyle=\bfseries,
  numberstyle=\ttfamily\footnotesize\color{codegray},
  basicstyle=\linespread{0.8}\ttfamily,%,\footnotesize,
  breakatwhitespace=false,
  breaklines=true,
  captionpos=b,
  keepspaces=true,
  numbers=left,
  columns=flexible,
  numbersep=5pt,
  showspaces=false,
  showstringspaces=false,
  showtabs=false,
  tabsize=2
}

%"mystyle" code listing set
\lstset{style=mystyle}


% Use to keep figure in same section
% \usepackage[section]{placeins}

\makeatletter
\font\uwavefont=lasyb10 scaled 652

\newcommand\colorwave[1][blue]{\bgroup\markoverwith{\lower3\p@\hbox{\uwavefont\textcolor{#1}{\char58}}}\ULon}
\makeatother

\ifx\paperversion\paperversiondraft
\newcommand\createtodoauthor[2]{%
\def\tmpdefault{emptystring}
\expandafter\newcommand\csname #1\endcsname[2][\tmpdefault]{\def\tmp{##1}\ifthenelse{\equal{\tmp}{\tmpdefault}}
   {\todo[linecolor=#2,backgroundcolor=#2,bordercolor=#2]{\textbf{#1:} ##2}}
   {\ifthenelse{\equal{##2}{}}{\colorwave[#2]{##1}\xspace}{ \todo[linecolor=#2,backgroundcolor=#2,bordercolor=#2]{\textbf{#1:} ##2}\colorwave[#2]{##1}}}}}
\else
\newcommand\createtodoauthor[2]{%
\def\tmpdefault{emptystring}
\expandafter\newcommand\csname #1\endcsname[2][\tmpdefault]{\def\tmp{##1}\ifthenelse{\equal{\tmp}{\tmpdefault}}
   {}
   {\ifthenelse{\equal{##2}{}}{##1\xspace}{ ##1}}}}
\fi

% Broaden margins to make room for todo notes
\ifx\paperversion\paperversiondraft
  \paperwidth=\dimexpr \paperwidth + 6cm\relax
  \oddsidemargin=\dimexpr\oddsidemargin + 3cm\relax
  \evensidemargin=\dimexpr\evensidemargin + 3cm\relax
  \marginparwidth=\dimexpr \marginparwidth + 3cm\relax
  \setlength{\marginparwidth}{4.6cm}
\fi

% We use the following color scheme
% 
% This scheme is both print-friendly and colorblind safe for
% up to four colors (including the red tones makes it not
% colorblind safe any more)
%
% https://colorbrewer2.org/#type=qualitative&scheme=Paired&n=4

\definecolor{pairedOneLightBlue}{HTML}{a6cee3}
\definecolor{pairedTwoDarkBlue}{HTML}{1f78b4}
\definecolor{pairedThreeLightGreen}{HTML}{b2df8a}
\definecolor{pairedFourDarkGreen}{HTML}{33a02c}
\definecolor{pairedFiveLightRed}{HTML}{fb9a99}
\definecolor{pairedSixDarkRed}{HTML}{e31a1c}

\createtodoauthor{grosser}{pairedOneLightBlue}
% \createtodoauthor{authorTwo}{pairedTwoDarkBlue}
\createtodoauthor{sid}{pairedThreeLightGreen}
\createtodoauthor{authorFour}{pairedFourDarkGreen}
\createtodoauthor{authorFive}{pairedFiveLightRed}
\createtodoauthor{authorSix}{pairedSixDarkRed}

%% Note: Authors migrating a paper from traditional SIGPLAN
%% proceedings format to PACMPL format should change 'sigplan' to
%% 'acmsmall'.


%% Some recommended packages.
\usepackage{booktabs}   %% For formal tables:
                        %% http://ctan.org/pkg/booktabs
\usepackage{subcaption} %% For complex figures with subfigures/subcaptions
                        %% http://ctan.org/pkg/subcaption
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{marvosym}

% [Operational semantics](https://tex.stackexchange.com/questions/271147/how-to-align-the-premises-in-a-semantic)
\renewcommand{\inference}[3][]{%
  \[\begin{array}[b]{@{}lc}
      \\
      \begin{array}[b]{l} #2 \end{array}
      \smash{\raisebox{-0.6\normalbaselineskip}{\scriptsize}} \\
      % \cline{2-2}
      \cmidrule[0.4pt]{1-1}
      \begin{array}[t]{l} #3 \end{array}
      \\
      \\
  \end{array}\]
}

% https://tex.stackexchange.com/questions/198462/the-lightning-symbol-in-an-equation-environment
%\newcommand{\lightning}{\mbox{\Lightning}}
\newcommand{\val}{\texttt{value} }
\newcommand{\unk}{\texttt{unk} }
\newcommand{\absent}{\texttt{absent} }
\newcommand{\case}{\texttt{case} }
\newcommand{\CONS}{\texttt{cons} }
\newcommand{\lzap}{\texttt{lz.ap} }
\newcommand{\lzthunk}{\texttt{lz.thunk} }
\newcommand{\construct}{\texttt{lz.construct} }
\newcommand{\stdcall}{\texttt{std.call} }
\newcommand{\std}{\texttt{std} }
\newcommand{\nofib}{\texttt{nofib} }
\newcommand{\Int}{\texttt{Int} }

\newcommand{\cpp}[1]{\mintinline{cpp}{#1}}
\newcommand{\raw}[1]{\mintinline{text}{#1}}
\newcommand{\denotation}[1]{\left\llbracket {\raw{#1}} \right\rrbracket}


\newcommand{\mlir}{\texttt{MLIR} }
\newcommand{\lz}{\texttt{lz} }
\newcommand{\lzforce}{\texttt{lz.force}}
\newcommand{\lzconstruct}{\texttt{lz.construct}}
\newcommand{\GHC}{\texttt{GHC} }
\newcommand{\ghc}{\GHC}
\newcommand{\Core}{\core}
\newcommand{\core}{\texttt{Core} }

% syntactic elements of our language
\newcommand{\EXPR}{\texttt{EXPR}}
\newcommand{\PHI}{\texttt{PHI}}
\newcommand{\BB}{\texttt{BB}}
\newcommand{\BBID}{\texttt{BBID}}
\newcommand{\INST}{\texttt{INST}}
\newcommand{\TERM}{\texttt{TERM}}
\newcommand{\LABEL}{\texttt{LABEL}}
\newcommand{\FLAG}{\texttt{FLAG}}
\newcommand{\ASSIGN}{\texttt{ASSIGN}}
\newcommand{\VID}{\texttt{VID}}

% transition relations
\newcommand{\assignarrow}{\xrightarrow{~\texttt{asgn}~}}
\newcommand{\phiarrow}{\xrightarrow{phi}}
\newcommand{\controlflowarrow}{\xrightarrow{~\texttt{ctrl}~}}


\makeatletter\if@ACM@journal\makeatother
%% Journal information (used by PACMPL format)
%% Supplied to authors by publisher for camera-ready submission
\acmJournal{PACMPL}
\acmVolume{1}
\acmNumber{1}
\acmArticle{1}
\acmYear{2017}
\acmMonth{1}
\acmDOI{10.1145/nnnnnnn.nnnnnnn}
\startPage{1}
\else\makeatother
%% Conference information (used by SIGPLAN proceedings format)
%% Supplied to authors by publisher for camera-ready submission
\acmConference[PL'17]{ACM SIGPLAN Conference on Programming Languages}{January 01--03, 2017}{New York, NY, USA}
\acmYear{2017}
\acmISBN{978-x-xxxx-xxxx-x/YY/MM}
\acmDOI{10.1145/nnnnnnn.nnnnnnn}
\startPage{1}
\fi


%% Copyright information
%% Supplied to authors (based on authors' rights management selection;
%% see authors.acm.org) by publisher for camera-ready submission
\setcopyright{none}             %% For review submission
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
%\setcopyright{rightsretained}
%\copyrightyear{2017}           %% If different from \acmYear


%% Bibliography style
\bibliographystyle{ACM-Reference-Format}
%% Citation style
%% Note: author/year citations are required for papers published as an
%% issue of PACMPL.
%\citestyle{acmauthoryear}  %% For author/year citations
%\citestyle{acmnumeric}     %% For numeric citations
%\setcitestyle{nosort}      %% With 'acmnumeric', to disable automatic
                            %% sorting of references within a single citation;
                            %% e.g., \cite{Smith99,Carpenter05,Baker12}
                            %% rendered as [14,5,2] rather than [2,5,14].
%\setcitesyle{nocompress}   %% With 'acmnumeric', to disable automatic
                            %% compression of sequential references within a
                            %% single citation;
                            %% e.g., \cite{Baker12,Baker14,Baker16}
                            %% rendered as [2,3,4] rather than [2-4].



\begin{document}

%% Title information
\title[Short Title]{Catching fire: Undefined behaviour for equational reasoning of lazy languages with strictness annotations}
                                        %% when present, will be used in
                                        %% header instead of Full Title.
\subtitle{Subtitle}                     %% \subtitle is optional


%% Author information
%% Contents and number of authors suppressed with 'anonymous'.
%% Each author should be introduced by \author, followed by
%% \authornote (optional), \orcid (optional), \affiliation, and
%% \email.
%% An author may have multiple affiliations and/or emails; repeat the
%% appropriate command.
%% Many elements are not rendered, but should be provided for metadata
%% extraction tools.

%% Author with single affiliation.
\author{First1 Last1}
\authornote{with author1 note}          %% \authornote is optional;
                                        %% can be repeated if necessary
\orcid{nnnn-nnnn-nnnn-nnnn}             %% \orcid is optional
\affiliation{
  \position{Position1}
  \department{Department1}              %% \department is recommended
  \institution{Institution1}            %% \institution is required
  \streetaddress{Street1 Address1}
  \city{City1}
  \state{State1}
  \postcode{Post-Code1}
  \country{Country1}
}
\email{first1.last1@inst1.edu}          %% \email is recommended

%% Author with two affiliations and emails.
\author{First2 Last2}
\authornote{with author2 note}          %% \authornote is optional;
                                        %% can be repeated if necessary
\orcid{nnnn-nnnn-nnnn-nnnn}             %% \orcid is optional
\affiliation{
  \position{Position2a}
  \department{Department2a}             %% \department is recommended
  \institution{Institution2a}           %% \institution is required
  \streetaddress{Street2a Address2a}
  \city{City2a}
  \state{State2a}
  \postcode{Post-Code2a}
  \country{Country2a}
}
\email{first2.last2@inst2a.com}         %% \email is recommended
\affiliation{
  \position{Position2b}
  \department{Department2b}             %% \department is recommended
  \institution{Institution2b}           %% \institution is required
  \streetaddress{Street3b Address2b}
  \city{City2b}
  \state{State2b}
  \postcode{Post-Code2b}
  \country{Country2b}
}
\email{first2.last2@inst2b.org}         %% \email is recommended

\begin{abstract}
% An abstract should consist of six main sentences:
%  1. Introduction. In one sentence, what’s the topic?
%  2. State the problem you tackle.
%  3. Summarize (in one sentence) why nobody else has adequately answered the research question yet.
%  4. Explain, in one sentence, how you tackled the research question.
%  5. In one sentence, how did you go about doing the research that follows from your big idea.
%  6. As a single sentence, what’s the key impact of your research?

% 1
We propose a new style of semantics
for non-strict languages that provide access to many optimizations that are
currently unsound for lazy languages.
% 2 
Lazy languages, while providing equational reasoning, are unable to reason
effectively about \emph{strictness annotations}. On the other hand, most strict
languages are impure, and thus unable to provide equational reasoning due to
the presence of side effects.
% 3
Research on optimizing non-strict languages has focused on optimizing away
non-strictness with demands, and efficient lowering of strictness onto modern
hardware.
% 4
We take a different approach: we propose to use undefined behaviour judiciously
while defining the semantics of our language to enable many key optimizations that
are possible in the strict world, that are not possible in the non-strict world.
We model \emph{divergent computations as undefined behaviour}, giving the
compiler far more freedom to optimize and reorder a mix of strict and non-strict
code.
\end{abstract}


% Only add ACM notes and keywords in camera ready version
% Drop citations and footnotes in draft and blind mode.
\ifx\paperversion\paperversioncamera
%% 2012 ACM Computing Classification System (CSS) concepts
%% Generate at 'http://dl.acm.org/ccs/ccs.cfm'.
\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10011007.10011006.10011008</concept_id>
<concept_desc>Software and its engineering~General programming languages</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10003456.10003457.10003521.10003525</concept_id>
<concept_desc>Social and professional topics~History of programming languages</concept_desc>
<concept_significance>300</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Software and its engineering~General programming languages}
\ccsdesc[300]{Social and professional topics~History of programming languages}
%% End of generated code


%% Keywords
%% comma separated list
\keywords{keyword1, keyword2, keyword3}  %% \keywords is optional

\else
\settopmatter{printacmref=false} % Removes citation information below abstract
\renewcommand\footnotetextcopyrightpermission[1]{} % removes footnote with conference information in first column
\fi

%% \maketitle
%% Note: \maketitle command must come after title commands, author
%% commands, abstract environment, Computing Classification System
%% environment and commands, and keywords command.
\maketitle
\ifx\grammarly\grammarlyon 
\onecolumn 
\else 
\fi

\section{Introduction}

% borrowed from : https://arxiv.org/abs/2003.00532 (Uday's note on MLIR)
Lazy languages such as Haskell
offer many benefits, chief of which is the ability to reason
equationally about programs. For performance, considerations,
the prototypical lazy language, Haskell, provides ``bang patterns'' to
mark strictness. Herein lies the trouble; these ``bang patterns'' do not
permit equational reasoning for the user. Worse, they form a sequence point
in the otherwise pure semantics, taking away most of the optimization freedom
from the compiler. We propose to remedy the situation by making judicious use
of \emph{undefined behaviour semantics}. While undefined behaviour is often
reviled in discourse, it is in fact a major reason why C and C++ can be optimized
as well as they can; defining certain rare or impossible conditions as undefined
behaviour provides the compiler a great deal of freedom by being able to ignore
these cases. We choose to mark \emph{divergence as undefined behaviour}. This
solves the \emph{correctness problem} in reordering strict computations; The
only thing our compiler (Lizzy) will reason about is performance when reordering
strict computations. Furthermore, this is not too insane a proposal; After all,
the C standard also defines side-effect free infinite loops as undefined behaviour.
Next, we show a variety of examples where this simple extension to the language
semantics permits far easier reasoning about mixing strictness and non-strictness.
We then put this to the test, by extending MLIR with a new non-strict IR, called
\lz. Note that the undefined behaviour semantics are critical in order to
reason effectively about the mix of strict and non strict behaviour we wish
to model within MLIR. Finally, to validate our approach, we consider a series
of benchmarks where our programming language, Lizzy outperforms similar programs
in Haskell compiled by the Glasgow Haskell Compiler.

% \begin{figure}
% % Link to figure
% %
% % https://docs.google.com/drawings/d/1juKp43D3rLC-luBQPwQZ_wCnDK2S_6C1k6USV0wKE0g/edit?usp=sharing
% \includegraphics[width=\columnwidth]{images/overview.pdf}
% \caption{Our key idea visualized}
% \end{figure}
                                                                   
% \grosser{Always state your contributions explicitly: (A) this makes it
% easy for the reader to understand what novelty is presented, and (B)
% these contributions help you to focus. In particular, the objectie of
% the remaining paper should be to support the claims stated here.
% }
Our contributions are:                                          
\begin{itemize}
\item A new dialect (\lz) for MLIR to encode these semantics, and provide modular
      non-strictness.
\item A translator from STG to \lz that exhibits the ability to 
      eliminate laziness and leverage MLIR's loop optimisation  framework.
\item A rewrite driven strategy for worker/wrapper that interleaves 
     worker/wrapper analysis along with worker/wrapper rewriting, by phrasing
     the worker/wrapper problem as an outlining/inlining problem.
\end{itemize}

\section{Stuff that doesn't work}
\begin{itemize}
\item circular references: SSA by default cannot handle circular references.
      We need to use the "relaxed SSA" that allows graphs. It's unclear how well
      this adapts.
\item A garbage collector. The usual story here, we don't really make a fair
      comparison.
\item Any realistic program exhibiting "difficult" laziness. I feel what would
      be interesting would be to implement, say, GRIN, along with a sophisticated
      pointer analysis using the MLIR analysis-as-rewrite story here.
\item A proof of correctness of the naive demand analysis I wrote.
\end{itemize}


\section{Stuff that does work}
\begin{itemize}
\item An encoding of laziness that works for the simple stuff I've tried
\item A simple version of "demand analysis" that eliminates first order laziness.
\item Some toy examples where we generate better IR than GHC because we can
     expose the "real work" to LLVM/MLIR in a way that they understand, by
     eliminating the noise that is laziness.
\end{itemize}

\section{What I feel would make a good paper/thesis}
\begin{itemize}
\item Our story of performing worker/wrapper by outlining/inlining is
\emph{intriguing}. I don't think it's \emph{strong}. So, to remedy that, we can:
\item (1) Make our laziness encoding bulletproof, connect to CBPV for example,
          handle circular references, etc.
\item (2) Make a strong case that MLIR is an interesting target for this breed of language.
          So, perform unification in MLIR, typeclass resolution in MLIR, perform some
          analysis/optimisation. Ths way, we show an end-to-end prototype of something that
          sorta works, instead of one thing that sorta works (?)
\end{itemize}


\textbf{TODO: fill in semantics here.}
\section{\lz: Its Syntax, Type system, semantics}
\subsection{A high level overview of \mlir}

\begin{figure*}
\begin{minted}{text}
toplevel := func | global
func := <fn-name> formal-param-list -> <ret-type> <region>
region := list [bb]
bb := <bb-name> formal-param-list : list inst; terminator-inst
inst := retval "=" <op-name> arg-list
terminator-inst := std.return(<name>) | br <name> | condbr <name> <bb1> <param-list> <bb2> <param-list>
\end{minted}
\caption{The \std dialect syntax}

\end{figure*}


\begin{figure*}
\vspace{3em}

\begin{tabular}{l l}
\begin{minipage}[t][1cm][b]{0.5\textwidth}
\inference[assign-cst]
{
}
{
  (\texttt{\%vid =}~ \texttt{std.constant } const, R) ~\assignarrow~R[\texttt{\%vid} \mapsto const]
}
\end{minipage}

&

\begin{minipage}[t][1cm][b]{0.5\textwidth}
\inference[assign-fncall]
{
  R[x_1] = v_1\quad R[x_2] = v_2\quad \dots\quad R[x_n] = v_n \\
  \denotation{f}(v_1, v_2, \dots, v_n) = y \\
}
{
  (\texttt{\%vid =}~ \texttt{f(}x_1, x_2, \dots, x_n \texttt{)}, R) ~\assignarrow~R[\texttt{\%vid} \mapsto y]
}
\end{minipage}
\end{tabular}

% =========================

\vspace{3em}
\begin{tabular}{l l}
\begin{minipage}[t][1cm][b]{0.5\textwidth}
\inference[cbr-left]
{
    % P[pc] = \texttt{cond\_br \%c $\caret$ bb1(...) \^bb2(...)} \quad
    P[pc] = \raw{condbr c ^bb1(xs) ^bb2(ys)} \\
    P[\raw{^bb1}] =  \raw{^bb1(ls)} \\
    R[c] \ne 0
}
{
    (pc, R) ~\controlflowarrow~(pc', R[ls \mapsto R[xs])
}

\end{minipage}
&
\begin{minipage}[t][1cm][b]{0.5\textwidth}

\inference[cbr-right]
{
    P[pc] = \texttt{br}~ c~ l(v_1)~ r(v_2) \quad
    P[r] = pc' \quad
    R[c] = 0
}
{
    (pc, R) ~\controlflowarrow~(pc', R[r.input \mapsto R[v_2])
}
\end{minipage}
\end{tabular}

% =========================

\inference[br]
{
    P[pc] = \texttt{br}~ n(v) \quad
    P[n] = pc'
}
{
    (pc, R) ~\controlflowarrow~(pc', R[n.input \mapsto R[v])
}

\caption{The operational semantics of the \std dialect}
\end{figure*}

\subsection{A high level overview of \lz}
We extend the basic \std dialect modestly, by adding primitives that can 
describe non-strictness. We first introduce a primitive known as \lzthunk,
which is responsible for creating non-strict thunks. 
To represent lazy function application, we introduce a new operation called \lzap,
which is the lazy sibling of \stdcall. This creates a thunk, which when evaluated,
invokes the function with the given arguments. To force
a thunk, we introduce \lzforce, which receives a thunk as input and returns
the forced value of the thunk as output. In effect, we have an encoding of
administrative normal form as (ANF) an MLIR dialect.

To represent algebraic data types, which enable reasoning of control flow 
and are the primary mode of abstraction in most functional languages, as
well as newer imperative languages such as Rust, we introduce the \construct
and \case operators, which are the introduction and elimination forms of
structured data in the dialect.

\begin{figure*}[hbt!]
\begin{minted}{text}
thunk(x): T -> Thunk<T>
ap(f, v1, v2, ..., vn): ((T1,...Tn) -> R) x T1 x ... Tn -> Thunk<R>
force(x): Thunk<T> -> T
construct(ConsName, v1, ..., vn): Symbol x T1 x T2 ... x Tn -> ADT<T>
case(x: T) of ... : ADT<T> -> R
\end{minted}
\caption{Syntax of \lz extensions}
\end{figure*}

\begin{figure*}
\vspace{3em}
\begin{tabular}{l l}
\begin{minipage}[t][1cm][b]{0.5\textwidth}
\inference[asgn-constructor]
{
   P[pc] = \\
    \quad \texttt{\%vid = lz.construct(@ConsName, \%x1, ..., \%xn)} \\
   P[\texttt{\%x1}] = v_1, \quad \dots, \quad P[\texttt{\%xn}] = v_n \\
}
{
  R[\texttt{\%vid} \mapsto \texttt{constructor(@ConsName, $v_1, \dots, v_n$)}]
}
\end{minipage}
&
\begin{minipage}[t][1cm][b]{0.5\textwidth}
\inference[asgn-thunk]
{
   P[pc] = \texttt{\%vid = lz.ap(\%fref, \%x1, ..., \%xn)} \\
   P[\texttt{\%f1}] = \texttt{ref(@fn)} \\
   P[\texttt{\%x1}] = v_1, \quad \dots, \quad P[\texttt{\%xn}] = v_n \\
}
{
  R[\texttt{\%vid} \mapsto \texttt{thunk(@fn, $v_1, \dots, v_n$)}]
}
\end{minipage}
\end{tabular}

% ================

\vspace{5em}
\begin{tabular}{l l}
\begin{minipage}[t][1cm][b]{0.5\textwidth}
\inference[asgn-case]
{
   P[pc] = \texttt{\%vid = lz.case(\%x, @Cons\textsubscript{1}, r\textsubscript{1},}\dots 
                    \texttt{, @Cons\textsubscript{N}, r \textsubscript{N})} \\
   \texttt{@Cons}_i = \texttt{@XCons} \\ 
   P[\texttt{\%x}] = \texttt{construct(@XCons, $v_1, \dots, v_n$)} \\
   r_i = \raw{ { ^entry(arg1, ..., argn): ... } }
}
{
  % decide on how to represent region execution
  (pc, R) \controlflowarrow (P[r_i], R[\texttt{arg}_i \mapsto v_i])
}
\end{minipage}
&
\begin{minipage}[t][1cm][b]{0.5\textwidth}
\inference[asgn-force]
{
   p[pc] = \texttt{\%vid = lz.force(\%thnk)} \\
   p[\texttt{\%thnk}] = \texttt{thunk(@fn, $v_1, \dots, v_n$)} \\
   \denotation{@fn}(v_1, v_2, \dots, v_n) = y
}
{
  r[\texttt{\%vid} \mapsto y]
}
\end{minipage}
\end{tabular}
\caption{Operational semantics of \lz  extensions}
\end{figure*}
\textbf{TODO: this is broken, because it doesn't scope properly. We need to describe \lzthunk
as building a thunk \emph{in memory/on the heap}, and the value stored in the register file
is the pointer to this thunk}.

\subsection{Purifying \lzforce}

Let us for a moment assume that divergence is not undefined behaviour. Now consider
the code in \autoref{fig:unused-divergent-variable-lz}. The variable called
\texttt{\%loopv} is unused. However, because divergence \texttt{\%loopv} is
divergent, it is incorrect to eliminate the variable definition of 
\texttt{\%loopv}, for the divergence of \texttt{loop} occurs when \texttt{\%loopt} is forced;
That is, when the instruction \texttt{\%loopv = lz.force(\%loopv)} is executed.
This implies that the instruction \lzforce is side-effecting.


If we wished to regain purity of \lzforce and leverage the power of
SSA, then we must be allowed to eliminate a call to \lzforce if the
value is unused. This is exactly the same requirement as being able to 
equationally reason with bangs in a \texttt{let} binding. In that use-case,
we wished for undefined behaviour semantics for ease-of-reasoning. Here, we wish
for undefined behaviour semantics for ease-of-optimization. 

\begin{lstlisting}[language=c++, caption=The SSA encoding of a lazy program with divergence in the \lz dialect.  Note the unused divergent variable \texttt{\%loopv}]
// loop = loop
lz.func @loop () -> !lz.adt<@Box> {
  %outt = lz.ap(@loop) : !lz.thunk<lz.adt<@Box>> 
  %outv = lz.force(@loop) : !lz.adt<@Box>
  lz.return(%outv) : !lz.value
}

// main = let !x = loop in 42
lz.func @main() -> !lz.adt<@Int> {
  %loopt = lz.ap(@loop) 
    : !lz.thunk<lz.adt<@Box>>
  %loopv = lz.force(%loopv) // <- unused %loopv
    : !lz.adt<@Box>
  %i = std.constant 42 : i64
  %retv = lz.construct(@Int, i)
  lz.return(%retv)
}
\end{lstlisting}
% \caption{The SSA encoding of a lazy program with divergence in the \lz dialect.
%          Note the unused divergent variable \texttt{\%loopv}}
% \label{fig:unused-divergent-variable-lz}
% \end{figure}


%\begin{figure}[hbt]
%\begin{minted}{text}
\begin{lstlisting}[language=c++, caption=Under the assumption that divergence is UB we can eliminate the call to \lzforce. This regains SSA semantics.]
// loop = loop
lz.func @loop () -> !lz.adt<@Box> {
  %outt = lz.ap(@loop) : !lz.thunk<lz.adt<@Box>> 
  %outv = lz.force(@loop) : !lz.adt<@Box>
  lz.return(%outv) : !lz.value
}

// main = let !x = loop in 42
lz.func @main() -> !lz.adt<@Int> {
  // %loopt = lz.ap(@loop) 
  //  : !lz.thunk<lz.adt<@Box>>
  // %loopv = lz.force(%loopv) 
  //   : !lz.adt<@Box> 
  %i = std.constant 42 : i64
  %retv = lz.construct(@Int, i)
  lz.return(%retv)
}
\end{lstlisting}
% \caption{Under the assumption that divergence is UB, we can eliminate the call to
%          \lzforce. Thus, this assumption allows us to regain SSA semantics.}
% \label{fig:unused-divergent-variable-lz-eliminated}
% \end{figure}



\subsection{Purifying \lzconstruct}

Consider the program in \autoref{fig:unused-construct}. For us to eliminate
the call to \texttt{lz.construct}, we need to be sure that memory allocation
has no side effects. In our case, since we assume that allocations are not
visible to the user in terms of their implementation details (eg. The address
of the pointer of the block of memory), we can safely remove the value
\texttt{\%unused = lz.construct(@Box)}  as \texttt{\%unused} is unused.


On the flipside, consider a program where we want to \emph{copy} the 
instruction \texttt{lz.construct}. If we were not guaranteed the existence
of a garbage collector, then this would not be pure; we would have created a
chunk of memory that is never freed. \textbf{TODO: Is there a good example where we 
want to copy a value for optimization? Something like, copy an SSA value both
into a loop and outside or something?}



\begin{lstlisting}[caption=An unused called to \lzconstruct]
lz.func() -> !hask.adt<@Box> {
  %unused = lz.construct(@Box)
  %one = std.constant 1 : i64
  lz.ret(%one) : i64
}
\end{lstlisting}

\section{Worker wrapper by local rewrites: A first stab}
In this section, we consider a small example program, which we will explain
how to perform a classical transform (the worker-wrapper transform) purely
by using local rewrites. Traditionally, such a transformation is performed
by first performing a \emph{demand analysis} whose results are used
to drive the rewrite.

We explore how this transformation can be achieved \emph{without} the need
for demand analysis by performing \emph{local rewrites}. This provides
both a simpler manifestation of the algorithm, as well as a potentially 
faster implementation, as the MLIR infrastructure is capable of performing
rewrites in parallel.
% \begin{figure}[htb!]
%\begin{minted}[linenos]{cpp}
{\footnotesize
\begin{lstlisting}[caption=initial source code]
SimpleInt f(Thunk<SimpleInt> i) {
    SimpleInt icons = force(i);
    int ihash = casedefault(icons);
    if (ihash <= 0) {
        return SimpleInt(42);
    } else {
        int prev = ihash - 1;
        SimpleInt siprev = SimpleInt(prev);
        Thunk<SimpleInt> siprev_t = thunkify(siprev);
        SimpleInt f_prev_v = apStrict(f, siprev_t);
        return f_prev_v;
    }
}

int main() {
    printf("%d\n", f(thunkify(SimpleInt(1))).v);
}
\end{lstlisting}
}
%\end{minted}
%\caption{Step 0: The source code we optimize using worker wrapper}
%\end{figure}

%\begin{figure}[htb!]
%\begin{minted}{cpp}
{\footnotesize
\begin{lstlisting}[caption=Step 1: outlining everything after the initial \lzforce into \texttt{f2}]
SimpleInt f2(SimpleInt icons) {
    int ihash = casedefault(icons);
    if (ihash <= 0) {
        return SimpleInt(42);
    } else {
        int prev = ihash - 1;
        SimpleInt siprev = SimpleInt(prev);
        Thunk<SimpleInt> siprev_t = thunkify(siprev);
        SimpleInt f_prev_v = apStrict(f, siprev_t);
        return f_prev_v;
    }
}

SimpleInt f(Thunk<SimpleInt> i) {
    SimpleInt icons = force(i);
    SimpleInt ret = apStrict(f2, icons);
    return ret;
}
\end{lstlisting}
}
%\caption{Step 1: outlining everything after the initial \lzforce into \texttt{f2}}
%\end{figure}

%\begin{figure}[htb!]
%\begin{minted}{cpp}
\begin{lstlisting}[language=c++, caption=Step 2: Removing the strict application]
SimpleInt f2(SimpleInt icons) {
    int ihash = casedefault(icons);
    if (ihash <= 0) {
        return SimpleInt(42);
    } else {
        int prev = ihash - 1;
        SimpleInt siprev = SimpleInt(prev);
        // Thunk<SimpleInt> siprev_t = thunkify(siprev);
        // SimpleInt f_prev_v = apStrict(f, siprev_t);
        Thunk<SimpleInt> f_prev_v = apStrict(f2, siprev);
        return f_prev_v;
    }
}

SimpleInt f(Thunk<SimpleInt> i) {
    SimpleInt icons = force(i);
    SimpleInt ret = apStrict(f2, icons);
    return ret;
}
\end{lstlisting}
%\end{minted}
%\caption{Step 2: Removing the strict application}
%\end{figure}

%\begin{figure}[htb!]
{\footnotesize
\begin{lstlisting}[language=c++, caption=Step 3: outline everything after casedefault into f3]
SimpleInt f3(int icons) {
    if (ihash <= 0) {
        return SimpleInt(42);
    } else {
        int prev = ihash - 1;
        SimpleInt siprev = SimpleInt(prev);
        Thunk<SimpleInt> f_prev_v = apStrict(f2, siprev);
        return f_prev_v;
    }
}

SimpleInt f2(SimpleInt icons) {
    int ihash = casedefault(icons);
    SimpleInt ret = apStrict(f3, ihash);
    return ret;
}

SimpleInt f(Thunk<SimpleInt> i) {
    SimpleInt icons = force(i);
    SimpleInt ret = apStrict(f2, icons);
    return ret;
}
\end{lstlisting}
}
%\caption{ Step 3: outline everything after casedefault(icons) into f3}
%\end{figure}

%\begin{figure}[htb!]
{\footnotesize
\begin{lstlisting}[language=c++, caption=replace call \texttt{f2(SimpleInt(prev))} to \texttt{f3(prev)}]
SimpleInt f3(int icons) {
    if (ihash <= 0) {
        return SimpleInt(42);
    } else {
        int prev = ihash - 1;
        Thunk<SimpleInt> f_prev_v = apStrict(f3, prev);
        return f_prev_v;
    }
}
SimpleInt f2(SimpleInt icons) {
    int ihash = casedefault(icons);
    SimpleInt ret = apStrict(f3, ihash);
    return ret;
}
SimpleInt f(Thunk<SimpleInt> i) {
    SimpleInt icons = force(i);
    SimpleInt ret = apStrict(f2, icons);
    return ret;
}
\end{lstlisting}
}
%\caption{Step 4: replace call f2(SimpleInt(prev)) to f3(prev)}
%\end{figure}


%\begin{figure}[htb!]
%% ! {\footnotesize
%% ! \begin{lstlisting}[language=c++]
%% ! SimpleInt f3(int icons) {
%% !     if (ihash <= 0) {
%% !         return SimpleInt(42);
%% !     } else {
%% !         int prev = ihash - 1;
%% !         Thunk<SimpleInt> f_prev_v = apStrict(f3, prev);
%% !         return f_prev_v;
%% !     }
%% ! }
%% ! SimpleInt f(Thunk<SimpleInt> i) {
%% !     SimpleInt icons = force(i);
%% !     int ihash = casedefault(icons);
%% !     SimpleInt ret = apStrict(f3, ihash);
%% !     return ret;
%% ! }
%% ! \end{lstlisting}
%% ! }
%\caption{Step 5: Inline f2 into f. This gives us the worker(f3) and wrapper(f)}
%\end{figure}

\section{Worker wrapper by local rewrites: Non-tail-calls}

Currently implementing the constructor simplification

\section{Worker wrapper by local rewrites: Sum types}


\section{Worker wrapper by local rewrites: Sum types + non-tail-calls}


\section{Demand analysis by rewrites: The full algorithm}

\begin{figure*}
\vspace{3em}
{\footnotesize
\begin{tabular}{l l}
\begin{minipage}[t][1cm][b]{0.5\textwidth}
% \begin{subfigure}[b]{0.48\textwidth}

\inference[ForceOfKnownAp]{
\texttt{\%x = ap(\%f, \%v1, ..., \%vn): !lz.thunk<T>} \\
\texttt{\%y = force(\%x): T}
}{
\texttt{\%y = \%f(\%v1, ..., \%vn): T}
}
\subcaption{force of a known function application: remove laziness}
\end{minipage}

&

\begin{minipage}[t][1cm][b]{0.5\textwidth}
\inference[ForceOfThunkify]{
\texttt{\%x = thunkify(\%v) : !lz.thunk<T>} \\
\texttt{\%y = force(\%x): T}
}{
\texttt{\%y = \%x}
}
\subcaption{force of a thunk: remove laziness}
\end{minipage}
\end{tabular}
}

% =========================
\vspace{15em}

\begin{tabular}{l l}
\begin{minipage}[t][1cm][b]{0.5\textwidth}
{\footnotesize

\inference{
% foo
\texttt{func f(\%x1, ... \%txi: thunk<T>, ..., \%xn) \{} \\
\texttt{  \%xi = force(\%txi)} \\
\texttt{  \%zi = ... ; \%tzi = thunkify(\%zi)} \\
\texttt{  f(\%y1, ..., \%tzi, ..., \%yn)} \\
\texttt{\}}
}{
\texttt{func f\_strict\_i(\%x1, ... \%xi: T, ..., \%xn) \{} \\
\texttt{   \%zi = ...} \\
\texttt{   f\_strict\_i(\%y1, ..., \%zi, ..., \%yn)} \\
\texttt{\}} \\
\texttt{func f(\%x1, ... \%txi: thunk<T>, ..., \%xn) \{} \\
\texttt{   \%xi = force(\%txi)} \\
\texttt{   \%zi = ...} \\
\texttt{   f\_strict\_i(\%y1, \%y2, ..., \%zi, ..., \%yn)} \\
\texttt{\}}
}
} % end footnotesize
\subcaption{outlining recursive call that is immediately forced}
\end{minipage}
&
\begin{minipage}[t][1cm][b]{0.5\textwidth}
{\footnotesize

\inference{
\texttt{func f(\%x1, ... \%wrapxi: @ADT, ..., \%xn) \{} \\
\texttt{   \%xi = case (\%wrapxi) [\@Wrapper -> \string^ entry(\%v) \{ return \%v \}]} \\
% \texttt{   \%zi = ...}
% \texttt{   \%wrapzi = construct(@Wrapper, \%zi)}
% \texttt{   f(\%y1, ..., \%wrapzi, ..., \%yn)}
\texttt{\}}
}{
\texttt{func f\_work\_i(\%x1, ... \%xi: T, ..., \%xn) \{} \\
\texttt{   \%zi = ...} \\
\texttt{   f\_strict\_i(\%y1, \%y2, ..., \%zi, ..., \%yn)} \\
\texttt{\}} \\
\texttt{func f(\%x1, ... \%txi: thunk<T>, ..., \%xn) \{} \\
\texttt{   \%xi = case (\%wrapxi) [\@Wrapper -> \string^ entry(\%v) \{ return \%v \}]} \\
\texttt{   \%zi = ...} \\
\texttt{   f\_work\_i(\%y1, ..., \%zi, ..., \%yn)} \\
\texttt{\}}
} % end inference
} % end footnotesize
\subcaption{outlining of recursion of a monovariant wrapper}
\end{minipage}
\end{tabular}

\vspace{15em}

\begin{tabular}{ll}
\begin{minipage}[t][1cm][b]{0.5\textwidth}
{\footnotesize
\inference{
\texttt{\%x = constructor(@Constructor, \%v1, ..., \%vm)} \\
\texttt{\%y = case \%x} \\
\texttt{      [\@C1 -> \{\string^entry1(\%z11, ..., \%z1n1): ...  \}]} \\
\texttt{      [...]} \\
\texttt{      [\@Ci -> \{\string^entry1(\%zi1, ..., \%zini): ...  \}]} \\
}{
\texttt{Inline \string^entryi with \%zik = \%vk}
}
} % end footnotesize
\subcaption{Case of known constructor: remove indirection}
\end{minipage}
&

\begin{minipage}[t][1cm][b]{0.5\textwidth}
{\footnotesize
\inference{
\texttt{data C = MkC(V) }\\
\texttt{@f(\%inc: C)} \\
\texttt{ case inc} \\
\texttt{   [C inv -> } \\
\texttt{     \%inv = extract(@MKC, \%inc) : V}\\
\texttt{     \%w = ... : V; \%wc = construct(@MKC, w) : C} \\
\texttt{     \%rec = apEager(@f, wc)]}\\
}{
\texttt{@frec(\%inv: V)}\\
\texttt{ \%inv = extract(@MKC, \%inc) : V}\\
\texttt{ \%w = ... : V; \%wc = construct(@MKC, w) : C} \\
\texttt{ \%rec = apEager(@f, wc)}\\
\texttt{@f(\%inc: C)} \\
\texttt{ \%inv = extract(\%inc) : V}\\
\texttt{ apEager(@frec, inv)}\\
}
} % end footnotesize
\subcaption{Outline recursive call of constructor that is immediately unwrapped}
\end{minipage}
% OutlineRecursiveApEagerOfConstructorPattern
\end{tabular}


\vspace{15em}
\begin{tabular}{ll}
\begin{minipage}[t][1cm][b]{0.5\textwidth}
{\footnotesize
\inference{
}{
BAR
}
} % end footnotesize
\subcaption{Outline pattern matching branches on a function input}
% OutlineCaseOfFnInput
\end{minipage}
&

\begin{minipage}[t][1cm][b]{0.5\textwidth}
{\footnotesize
\inference{
\texttt{data C = MKC(V) }\\
\texttt{@f(...)}\\
\texttt{  ...}\\
\texttt{  \%out = constructor(C, \%w)}\\
\texttt{  lz.return (\%out)}\\
}{
\texttt{data C = MKC(V) }\\
\texttt{@finner(...)} \\
\texttt{ ...} \\
\texttt{ lz.return \%w} \\
\texttt{ } \\
\texttt{@f(...)}\\
\texttt{ \%w = call \%f(...)}\\
\texttt{ \%out = constructor(C, \%w)}\\
\texttt{ lz.return (\%out)}
}
} % end footnotesize
\subcaption{Outline return of constructor}
% outline return of constructor
\end{minipage}
\end{tabular}
%% 
%% 
%% \begin{minipage}[t][1cm][b]{0.5\textwidth}
%% {\footnotesize
%% \inference{
%% FOO
%% }{
%% BAR
%% }
%% } % end footnotesize
%% \subcaption{Peel constructor from case}
%% % peel constructor from case
%% \end{minipage}
\caption{Local rewrites performed to eliminate laziness (2)}
\end{figure*}


\section{Evaluation}

As a baseline, we compare our performance on \nofib test-suite, which is the
test suite that GHC is tested with and performance improvements to GHC 
are reported on. We only consider a representative subset of programs from \nofib;
The full test suite also extensively tests Haskell's semantics of parallelism, 
software transactional memory, and other features that are orthogonal to the
problem of representing and optimizing non strictness.

\section{Related Work}

\subsection{Demand analysis}
\cite{wadler1987projections} ``Projections for demand analysis'' performs
demand analysis computation by modelling demands as projections on the semantic
domain. We use their broad framework, adapted to our setting. 

\cite{grafcall}, \cite{breitner2014call} extend the demand analysis with
finer grained information, such as Call Arity analysis.

\subsection{GHC's intermediate representation}

The Glasgow Haskell compiler \cite{jones1993glasgow} is a mature optimizing
compiler for Haskell, whose plugin infrastructure we hook into to  develop a test
set for \lz, and whose demand analysis we use as a benchmark to measure against.

\subsection{Intel Haskell research compiler IR}
The Intel labs Haskell Research compiler \cite{liu2013intel} models Core in a
strict ANF language. The compiler performs demand analysis and abstract
simplification on ANF. The demand analysis is performed using traditional
abstract interpretation techniques. Later, this demand information is used
to interpret the program and perform abstract simplification. (TODO: figure out
details of this step).

It then compiles to an intermediate representation called MIL,
which is a loosely typed CFG based, SSA-lite intermediate representation.  They
represent laziness as heap values, and manipulate the heap. Thus, their
representation and usage of lazy values reasons with memory, instead of
providing value semantics.
MIL also does not have a notion of nested regions. Therefore, MIL extends
the traditional control flow controls with more finer-grained information,
called as \texttt{cut} and \texttt{interproc}.


\subsection{Mixing dataflow analysis and transformation}

This is based on the theory of compositional dataflow analysis
and transformations, \cite{lerner2002composing} 
which proves that we can interleave dataflow analyses and transformations
safely.

Hoopl \cite{ramsey2010hoopl} is the dataflow analysis and transformation library
within GHC. However, GHC does not use this for performing dataflow analysis
over Core, as the Hoopl library is designed to work with a CFG based
intermediate representation, while GHC Core is a typed functional, expression
oriented intermediate representation. While Hoopl is used for certain simplifications
within C-- in GHC, it is not used extensively due to  poor performance characteristics
exhibited by the implementation. (TODO: bench Hoopl on contrived examples)

\subsection{Alternative encodings of laziness}

GRIN  \cite{boquist1996grin} is an alternative intermediate representation
for lazy and strict functional programming languages which explicitly represents
heap manipulation and case analysis. However, it is not SSA based.

\subsection{Theoretical justification for our encoding}

Our encoding is based on call-by-push-value \cite{levy2012call}, which
breaks down call-by-value and call-by-name paradigms into simple primitives. In
our dialect \lz, we expose these primitives to enable a clean mixture of
call by name and call by value. This enjoys the many properties that
are proven to hold for call-by-push-value (TODO: which ones?!)


\subsection{Technology substrate}
                                                         
MLIR \cite{lattner2020mlir} is a compiler framework for building reusable and
extensible compiler infrastructure.  MLIR aims to address software
fragmentation, improve compilation for heterogeneous hardware, significantly
reduce the cost of building domain specific compilers, and aid in connecting
existing compilers together.

\section{Conclusion}

We provide a baseline implementation of non-strictness for the MLIR framework
which with very minimal extensions, allows us to fully express non strict semantics
while being compatible with the rest of MLIR's strict dialects.
As an experience report, we explore MLIR's strengths and weaknesses at representing
non-strictness within an SSA based framework. We also provide a baseline implementation
of demand analysis, as inspired by Wadler and Hugh's ``projections for demand
analysis''. We evaluate our example programs against the nofib benchmark test suite.
We also provide provocative examples where the potent combination of MLIR's 
loop optimization infrastructure along with our modest extensions allows us to
beat native haskell's performance.

\section{TODO}

\subsection{Performance benchmarking}
\subsection{Correct encoding for mutual recursion}
\subsection{Correct encoding for partially applied functions/closures}

We currently have a \texttt{lz.lambda} but it's basically untested, because
we didn't have many things that used closures. We need to make sure this
works properly, and encodes data correctly.

\subsubsection{Lambdas in GRIN}
GRIN is also a low level IR, so it's useful to recall how this is encoded
within GRIN. To quite the GRIN thesis:

\say{
end. Using hbcc we get well optimised
code in a low level functional style, comparable to for example the Core lan-
guage [PJ96] used by the Glasgow Haskell compiler.  The code is lambda lifted,
i.e., has only super combinators, and most high level Haskell constructions,
like overloading, have been transformed away.
}


\subsubsection{Implementing lambda lifting}
Recall that optimal lambda lifting is $O(n^2)$. I don't know the
algorithm; I'd have to study it before I implement it.

\subsection{Stretch: Separate dialect for pattern matching}
\subsection{Stretch: rewrite based demand analysis}
\subsection{Stretch: rewrite based unification}
We introduce a dialect for performing unification.


\subsection{Stretch: rewrite based tabled typeclass unification}
\subsection{Stretch: As static as possible garbage collection}


%% Acknowledgments
\begin{acks}                            %% acks environment is optional
                                        %% contents suppressed with 'anonymous'
  %% Commands \grantsponsor{<sponsorID>}{<name>}{<url>} and
  %% \grantnum[<url>]{<sponsorID>}{<number>} should be used to
  %% acknowledge financial support and will be used by metadata
  %% extraction tools.
  This material is based upon work supported by the
  \grantsponsor{GS100000001}{National Science
    Foundation}{http://dx.doi.org/10.13039/100000001} under Grant
  No.~\grantnum{GS100000001}{nnnnnnn} and Grant
  No.~\grantnum{GS100000001}{mmmmmmm}.  Any opinions, findings, and
  conclusions or recommendations expressed in this material are those
  of the author and do not necessarily reflect the views of the
  National Science Foundation.
\end{acks}

%% Bibliography

%% why does this not show?
\bibliography{references}

%% Appendix
\appendix
\section{Appendix}

Text of appendix

\end{document}
